{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate4(file, logs, method, threshold, dataset):#-------------------EVALUATE4\n",
    "    groupsDictOut = []\n",
    "    groupsDictOut.append([\"Super_Word\", \"Value\"])\n",
    "    wordsSeen = {}\n",
    "    groups = {}\n",
    "    itemsSeen = {}\n",
    "    #var dictionary\n",
    "    #file                                           #raw input file\n",
    "    #start                                          #starting point for intervals\n",
    "    #end                                            #end point for current interval\n",
    "    count = Counter()                               #counter for frequencies\n",
    "    timeSlice = 1                                   #timeSlice ID\n",
    "    newIdea = 'false'                               #true/false:\n",
    "                                                        #new bin in the time slice?\n",
    "    newIdeaCount = 0                                #number of new ideas so far\n",
    "    totalIdeas = 0                                  #total ideas per timeSlice\n",
    "    output = []                                     #output array\n",
    "    i = 0                                           #index for while loop\n",
    "    model = models.Word2Vec.load(\"text8Model\")\n",
    "    #file.sort(key=itemgetter(3))\n",
    "    \n",
    "    logs.append([\"--------------- START EXECUTION ---------------\"])\n",
    "    if(INTERVAL_MODE == 'time'):\n",
    "        start = int(file[0][3])                     #unix time of first row\n",
    "        end = start + INTERVAL\n",
    "    elif(INTERVAL_MODE == 'count'):\n",
    "        start = 0\n",
    "        end = start + INTERVAL\n",
    "        \n",
    "    #output.append([\"Time Slice\",                        #file header\n",
    "    #            \"New Category?\", \n",
    "    #            \"# of New Categories\", \n",
    "    #            \"Total Ideas in Time Slice\",\n",
    "    #            \"Probability of New Bin\",\n",
    "    #            \"%New Categories in Time Slice\",\n",
    "    #            \"%New Categories Overall\",\n",
    "    #            \"Counter\"])\n",
    "    logs.append([str(timeSlice) + \"------ TIME_SLICE\" + str(timeSlice) + \" -----\"])\n",
    "    while(i < len(file)):                                   #while more ideas still exist\n",
    "        line = file[i]                                      #a line in a file\n",
    "        if(INTERVAL_MODE == 'time'):\n",
    "            current = int(line[3])\n",
    "        elif(INTERVAL_MODE == 'count'):\n",
    "            current = i          \n",
    "        if(current <= end):                            #for each time slice\n",
    "            format(line)                                    #convert idea content to list of relivant words\n",
    "            logs.append([\"\\tIDEA \" + str(i) + \" -----\"])\n",
    "            # print groupType\n",
    "            groupList = []\n",
    "            for word in line[1]:                            #add to counter\n",
    "                if(method == \"nltk\"):\n",
    "                    group = getGroup(count, word, threshold, wordsSeen, groups)\n",
    "                elif(method == \"word2vec\"):\n",
    "                    group = getGroup3(count, word, model, threshold, wordsSeen, groups)\n",
    "                oldCount = count[group]\n",
    "                count[group] += 1\n",
    "                newCount = count[group]\n",
    "                #groupList.append(group)\n",
    "\n",
    "                if newCount == 1:                           #was this a new bin?\n",
    "                    newIdea = 'true'                            #if yes,\n",
    "                    newIdeaCount += 1\n",
    "                totalIdeas += 1\n",
    "                logs.append([\"\\t\\t\" + word + \":\\t\" + group + \"--> \\t\" + str(newCount)])\n",
    "            for group in groupList:\n",
    "                print group\n",
    "            \n",
    "            #COMBOS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            #groupList = getCombos(groupList)\n",
    "            #for combo in groupList:\n",
    "            #    oldCount = count[combo]\n",
    "            #    count[combo] += 1\n",
    "            #    newCount = count[combo]\n",
    "            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!    \n",
    "            #    if(newCount == 1 and newIdea == \"false\"):\n",
    "            #        newIdeaCount += 1\n",
    "            #    logs.append([\"\\t\\t\" + str(line[1]) + \":\\t\" + combo + \"--> \\t\" + str(newCount)])\n",
    "            i += 1\n",
    "        else:                                                   #at the end of each time slice\n",
    "            if(totalIdeas > 0):\n",
    "                output.append([timeSlice, newIdea, newIdeaCount, totalIdeas])\n",
    "                estimateNewIdea(count, output[timeSlice - 1])\n",
    "                calculateCat(count, output, timeSlice - 1, newIdeaCount, totalIdeas)\n",
    "                timeSlice += 1                                  #increment time slice id\n",
    "                logs.append([str(timeSlice) + \"------ TIME_SLICE\" + str(timeSlice) + \" -----\"])\n",
    "                \n",
    "            start = end                                         #update time slice markers\n",
    "            end = start + INTERVAL\n",
    "            newIdea = 'false'\n",
    "            newIdeaCount = 0\n",
    "            totalIdeas = 0\n",
    "    if(totalIdeas > 0):\n",
    "        output.append([timeSlice, newIdea, newIdeaCount, totalIdeas])\n",
    "        estimateNewIdea(count, output[timeSlice -1])\n",
    "        calculateCat(count, output, timeSlice - 1, newIdeaCount, totalIdeas)\n",
    "    #print count\n",
    "    dictionary_to_save = \"Dictionaries/wordkeyMyData_%s_%s_%.2f\" %(dataset, method, threshold)\n",
    "    dictionary_out = open(dictionary_to_save, 'w')\n",
    "    dictionary_out.write(json.dumps(wordsSeen, indent=2))\n",
    "    dictionary_out.close()\n",
    "    for key in groups.keys():\n",
    "        groupsDictOut.append([key, groups.get(key)])\n",
    "    \n",
    "    \n",
    "    for line in groupsDictOut:\n",
    "        print line\n",
    "    print count\n",
    "    writeOut(groupsDictOut, \"Dictionaries/groupkeyMyData_%s_%s_%.2f.csv\" %(dataset, method, threshold))\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate6(file, logs):#-------------------------------------------------EVALUATE6\n",
    "    #datasets = ['SuperBoring',\n",
    "    #             'Boring',\n",
    "    #             'Normal',\n",
    "    #             'NewAtEnd',\n",
    "    #             'Exciting']              #the list of input filenames\n",
    "    datasets = ['smallIdeas']\n",
    "    # versions = [evaluate4(file, logs, \"getGroup\", 0.5)]       #array of functions to try out\n",
    "    #             evaluate4(file, logs, \"getGroup\", 0.9),\n",
    "    #             evaluate4(file, logs, \"getGroup3\", 0.5),\n",
    "    #             evaluate4(file, logs, \"getGroup3\", 0.9)]\n",
    "    #methods = [\"nltk\", \"word2vec\"]\n",
    "    methods = [\"word2vec\"]\n",
    "    # method_names = {\"getGroup\": 'nltk', 'getGroup3': 'word2vec'}\n",
    "    thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    #thresholds = [0.6]\n",
    "    vText = ['nltk 0.5','nltk 0.9',                 #strings associated with the function of \n",
    "             'word2vec 0.5','word2vec 0.9']                       \n",
    "                                                    #\"versions[]\"\n",
    "    output = []                                     #output to be sent to csv\n",
    "    outLine = []                                    #one line of output taken from \"returnedOut\"\n",
    "    # i = 0\n",
    "\n",
    "    output.append([\"dataset\", \"method\",             #header\n",
    "               \"timeSlice\", \"GT_predict\", \"true\"])\n",
    "    \n",
    "    \n",
    "\n",
    "    for dataset in datasets:                     #for each dataset\n",
    "        for theme, theme_data in dataset.groupby(\"theme\"):\n",
    "            input_file = \"Input/%s.csv\" %dataset\n",
    "            print \"datasets: \", dataset\n",
    "            print \"theme: \", theme\n",
    "            # j = 0                   \n",
    "            # for function in versions:                       #run each version of the program\n",
    "            for method in methods:\n",
    "                print \"method: \", method\n",
    "                for threshold in thresholds:\n",
    "                    print \"threshold: \", threshold\n",
    "                    opened_input = getInputFile(input_file)\n",
    "                    returnedOut = evaluate4(opened_input, logs, method, threshold, dataset)                      #output from this version\n",
    "                    print \"\\treturnedOut: \", returnedOut\n",
    "                    for line in returnedOut:                    #rotate output to desired format\n",
    "                        print \"\\t\\tline: \", line                    #and save to \"output[]\"\n",
    "                        outLine = []\n",
    "                        outLine.append(dataset)\n",
    "                        outLine.append(\"%s_%.2f\" %(method, threshold))\n",
    "                        outLine.append(line[0])\n",
    "                        outLine.append(line[4])\n",
    "                        outLine.append(line[5])             \n",
    "                        print \"\\t\\t\\t\", outLine\n",
    "                        output.append(outLine) \n",
    "            # j = j+1                       \n",
    "        # i = i+1\n",
    "    writeOut(output, OUTPUT_FILE)\n",
    "\n",
    "def errorLog(errorCode):#---------------------------------------------ERROR_LOG\n",
    "    if(errorCode == 0):\n",
    "        return \"ERROR: NO VERSION SPECIFIED\"\n",
    "    else:\n",
    "        return \"THERE WAS AN ERROR\"\n",
    "        \n",
    "    \n",
    "def writeOut(output, fileName):#--------------------------------------WRITE_OUT\n",
    "    #var dictionary\n",
    "    #filename                                       #file to write to\n",
    "    #output                                         #data to write\n",
    "    #writer                                         #csv writer object\n",
    "    \n",
    "    with open(fileName, 'w') as file:               \n",
    "        writer = csv.writer(file)\n",
    "        for row in output:\n",
    "            writer.writerow(row)\n",
    "        if(output == logs):\n",
    "            print \"Log file written to \", fileName\n",
    "        else:\n",
    "            print \"Results written to \", fileName\n",
    "            logs.append([\"Results written to \" + fileName])\n",
    "\n",
    "#--------------------------------------------------------------------------MAIN\n",
    "\n",
    "INPUT_FILE = \"Input/Normal.csv\"            \n",
    "OUTPUT_FILE = \"Data Output/MyDataWord2VecWithStemming.csv\"\n",
    "LOG_FILE = \"MyDataWord2VecWithStemming.txt\"\n",
    "VERSION = 6\n",
    "INTERVAL_MODE = 'count'                              #options: time, count;\n",
    "                                                    #options: words, categories;\n",
    "#INTERVAL = 60000                                    #1 minute\n",
    "#INTERVAL = 600000                                    #10 minutes\n",
    "#INTERVAL = 1800000                                  #30 minutes\n",
    "#INTERVAL = 3600000                                  # 1 hour\n",
    "INTERVAL = 3\n",
    "out = []                                            #data output to print\n",
    "logs = []                                           #log  output to print\n",
    "#f = open('dictNLTK.file', 'r')\n",
    "#word2Vec = eval(f.read())                          #dictionary in key-value form where\n",
    "                                                        #key = words and their synonymns\n",
    "                                                        #value = the group that is entered\n",
    "                                                            #the counter for that word\n",
    "#f.close()\n",
    "\n",
    "#f = open('dict.file', 'r')\n",
    "#nltk = eval(f.read())\n",
    "#f.close()\n",
    "\n",
    "#wordsSeen = {}\n",
    "#itemsSeen = {}\n",
    "\n",
    "#getInput\n",
    "file = getInputFile(INPUT_FILE)\n",
    "\n",
    "#setup Log File\n",
    "logs.append([\"VERSION:\\t\" + str(VERSION)])\n",
    "logs.append([\"INPUT_FILE:\\t\" + INPUT_FILE])\n",
    "logs.append([\"INTERVAL_MODE:\\t\" + INTERVAL_MODE])\n",
    "\n",
    "#process\n",
    "if(VERSION == 1):\n",
    "    out = evaluate(file)\n",
    "elif(VERSION == 2):\n",
    "    out = evaluate2(file)\n",
    "elif(VERSION == 3):\n",
    "    out = evaluate3(file)\n",
    "elif(VERSION == 4):\n",
    "    out = evaluate4(file, logs)\n",
    "elif(VERSION == 5):\n",
    "    out = evaluate5(file, logs)\n",
    "elif(VERSION == 6):\n",
    "    evaluate6(file, logs)\n",
    "else:\n",
    "    print \"NO VERSION SPECIFIED\"\n",
    "    logs.append([errorLog(0)])\n",
    "    writeOut(logs, LOG_FILE)\n",
    "    quit()\n",
    "\n",
    "#print wordsSeen\n",
    "#countUniqueWords(file)\n",
    "\n",
    "#print output to screen\n",
    "#f = open('dictNLTK.file', 'w')\n",
    "#f.write(str(word2Vec))\n",
    "#f.close()\n",
    "\n",
    "#f = open('dict.file', 'w')\n",
    "#f.write(str(nltk))\n",
    "#f.close()\n",
    "\n",
    "#for line in out:\n",
    "#   print line\n",
    "\n",
    "#VERSION 1:     basic; category as bin              IN-PROGRESS -- functional\n",
    "#               INPUTS:\n",
    "#                   ideas.csv\n",
    "#               TODO:\n",
    "#                   - implement log\n",
    "#VERSION 2:     words as bins                       IN-PROGRESS -- functional   \n",
    "#               INPUTS:\n",
    "#                   ideas2.csv\n",
    "#               TODO:\n",
    "#                   - implement log\n",
    "#VERSION 3:     words as bins; separate by theme    IN-PROGRESS -- not functional\n",
    "#               INPUTS:\n",
    "#                   ideas_corrected.csv\n",
    "#                   smallIdeas.csv\n",
    "#               TODO:\n",
    "#                   - fix bugs that arose in compilation\n",
    "#                   - implement log\n",
    "#VERSION 4:     super-words as bins                 IN-PROGRESS -- functional\n",
    "#               INPUTS:\n",
    "#                   ideas_corrected.csv\n",
    "#                   smallIdeas.csv\n",
    "#               TODO:\n",
    "#                   improve time/accuracy \n",
    "#VERSION 5:     super-words as bins;                IN-PROGRESS -- functional\n",
    "#               separate by theme\n",
    "#               TODO:\n",
    "#                   - flip data \n",
    "#VERSION 6:     full test                           IN-PROGRESS -- not functional\n",
    "\n",
    "#printResults\n",
    "#writeOut(out, OUTPUT_FILE)\n",
    "writeOut(logs, LOG_FILE)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
